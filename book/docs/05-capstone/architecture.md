# Capstone Project: Architecture

## System Overview

The capstone project is a complete, autonomous humanoid robot that:
1. Perceives the environment (camera, LiDAR)
2. Understands natural language commands via voice
3. Plans tasks using language understanding
4. Executes actions through ROS 2 control
5. Adapts based on sensor feedback

## Architecture Diagram

Coming soon.

## Components

1. **Perception Module** — Camera + LiDAR processing
2. **Planning Module** — LLM-based task decomposition
3. **Control Module** — Joint controllers via ROS 2 actions
4. **Voice Interface** — Speech recognition + LLM integration

---

**Next**: [Setup](setup.md)
